{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4gWZmcOAmFl",
        "outputId": "a26304dd-c706-49b6-b93c-688d59d7cc79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"summary\": \"Artificial Intelligence (AI) and Machine Learning (ML) are revolutionizing industries by enabling computers to learn from data, leading to improved efficiency and decision-making across various fields. Their applications range from healthcare and finance to transportation and beyond.\"}\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "import json\n",
        "\n",
        "# Initialize the Hugging Face inference client\n",
        "client = InferenceClient(api_key=\"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\")\n",
        "\n",
        "# Define the message for summarization\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Summarize the following text in one or two sentences: 'Artificial Intelligence and Machine Learning are transforming industries by enabling computers to learn from data. This has applications in healthcare, finance, transportation, and more, improving efficiency and decision-making across various fields.'\"},\n",
        "]\n",
        "\n",
        "# Perform inference and stream the response\n",
        "try:\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "        max_tokens=100,\n",
        "        top_p=0.7,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    response_text = []\n",
        "    for chunk in stream:\n",
        "        response_text.append(chunk.choices[0].delta.content)\n",
        "\n",
        "    # Join all chunks into a single formatted string\n",
        "    summarized_text = \"\".join(response_text)\n",
        "\n",
        "    # Create a JSON response\n",
        "    json_response = json.dumps({\"summary\": summarized_text})\n",
        "\n",
        "    # Print the JSON response\n",
        "    print(json_response)\n",
        "\n",
        "except Exception as e:\n",
        "    # Handle any errors that occur during inference\n",
        "    error_response = json.dumps({\"error\": str(e)})\n",
        "    print(error_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "uwPMYztvBYzO",
        "outputId": "995c24c1-e6e4-4dbe-a85c-42ee16f4203a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df9ad9d7-bb75-4d08-a51b-931c9ea09beb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-df9ad9d7-bb75-4d08-a51b-931c9ea09beb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Install PyMuPDF if not already installed\n",
        "import fitz  # PyMuPDF\n",
        "import json\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# Upload your PDF file in Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract text from the uploaded PDF file\n",
        "pdf_text = \"\"\n",
        "for filename in uploaded.keys():\n",
        "    with fitz.open(filename) as pdf_document:\n",
        "        for page_num in range(pdf_document.page_count):\n",
        "            page = pdf_document[page_num]\n",
        "            pdf_text += page.get_text(\"text\") + \"\\n\"  # Extract text from each page\n",
        "\n",
        "# Optionally display extracted text (to verify content)\n",
        "print(\"Extracted Text from PDF (first 1000 characters):\\n\", pdf_text[:1000])  # Display the first 1000 characters as a sample\n",
        "\n",
        "# Initialize the Hugging Face inference client\n",
        "client = InferenceClient(api_key=\"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\")\n",
        "\n",
        "# Prepare a summarization message (you may need to truncate the text for very long PDFs)\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": f\"Please summarize the following text: '{pdf_text[:5000]}'\"}  # Limit to first 5000 characters\n",
        "]\n",
        "\n",
        "# Stream the summary\n",
        "response_text = []\n",
        "try:\n",
        "    stream = client.chat.completions.create(\n",
        "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "        max_tokens=500,\n",
        "        top_p=0.7,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    # Collect response chunks\n",
        "    for i, chunk in enumerate(stream):\n",
        "        response_text.append(chunk.choices[0].delta.content)\n",
        "\n",
        "        # Add a newline after every 4 chunks for readability\n",
        "        if (i + 1) % 40 == 0:\n",
        "            response_text.append(\"\\n\")\n",
        "\n",
        "    # Join all chunks into a single formatted string\n",
        "    summarized_text = \"\".join(response_text)\n",
        "\n",
        "    # Create a JSON response\n",
        "    json_response = json.dumps({\"summary\": summarized_text})\n",
        "\n",
        "    # Print the JSON response\n",
        "    print(json_response)\n",
        "\n",
        "except Exception as e:\n",
        "    # Handle any errors that occur during inference\n",
        "    error_response = json.dumps({\"error\": str(e)})\n",
        "    print(error_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW-j18N_CLn8",
        "outputId": "e3a6f91c-fa9a-4550-ac9f-aa3b2ff7efbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.12.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (3.0.2)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok huggingface-hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "hQjt2hIeGluC",
        "outputId": "37e78573-ebe8-430c-a976-61998d94c8c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-411b8d58-618c-43e7-9fc0-216548d13bf6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-411b8d58-618c-43e7-9fc0-216548d13bf6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Shreya Sawant Resume..pdf to Shreya Sawant Resume. (1).pdf\n",
            "Extracted Text from PDF:\n",
            " SHREYA MANGESH SAWANT\n",
            "1/3 Dennis House , Padwal Nagar , Thane - 400604\n",
            "9326737009\n",
            "shreyasawantm13@gmail.com\n",
            "SHREYA MANGESH SAWANT\n",
            "1/3 Dennis House , Padwal Nagar , Thane - 400604\n",
            "9326737009\n",
            "shreyasawantm13@gmail.com\n",
            "   Respected Sir/ Madam \n",
            "                 I am writing to express my strong desire to work at the Executive level position\n",
            "at your esteemed organisation .Having worked extensively I am confident that I have the\n",
            "ability to contribute to the success of your organisation.\n",
            "\n",
            "-\n",
            "-\n",
            "SHREYA MANGESH SAWANT\n",
            "1/3 Dennis House , Padwal Nagar , Thane - 400604\n",
            "9326737009\n",
            "shreyasawantm13@gmail.com\n",
            "Objective\n",
            "A highly motivated Commerce graduate want to seek opportunity to get flourish in the\n",
            "field of Accounting and Taxation by working in an esteemed organization like you\n",
            "Experience\n",
            "Haren Sanghvi and Associates\n",
            "Taxation Officer\n",
            "Jan 2024 present\n",
            "Sumaria and Sumaria\n",
            "Accounts Officer\n",
            "Jun 2023 - Dec 2023\n",
            "Education\n",
            "Course / Degree\n",
            "School / University\n",
            "Grade / Score\n",
            "Year\n",
            "BACHELOR OF COMMERCE\n",
            "KJ Somai\n"
          ]
        }
      ],
      "source": [
        "import fitz  # PyMuPDF\n",
        "from google.colab import files\n",
        "\n",
        "# Upload your PDF file in Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract text from the uploaded PDF file\n",
        "pdf_text = \"\"\n",
        "for filename in uploaded.keys():\n",
        "    with fitz.open(filename) as pdf_document:\n",
        "        for page_num in range(pdf_document.page_count):\n",
        "            page = pdf_document[page_num]\n",
        "            pdf_text += page.get_text(\"text\") + \"\\n\"  # Extract text from each page\n",
        "\n",
        "# Display extracted text (optional, to verify content)\n",
        "print(\"Extracted Text from PDF:\\n\", pdf_text[:1000])  # Display the first 1000 characters as a sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "jGqGcwXqHFWb",
        "outputId": "31928232-735c-46d8-c35c-9b78afd16b62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-457988ec-8515-4173-95c8-b97d82bdb852\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-457988ec-8515-4173-95c8-b97d82bdb852\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Shruti Sawant new resume (1).pdf to Shruti Sawant new resume (1).pdf\n",
            "{\n",
            "  \"summary\": \"I'd be happy to help, but you haven't provided any text for me to summarize. Please share the text you'd like me to summarize, and I'll do my best to craft a compelling and impressive summary that will surely win over the judges.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import fitz  # PyMuPDF\n",
        "from google.colab import files\n",
        "import json\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# Upload your PDF file in Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract text from the uploaded PDF file\n",
        "pdf_text = \"\"\n",
        "for filename in uploaded.keys():\n",
        "    with fitz.open(filename) as pdf_document:\n",
        "        for page_num in range(pdf_document.page_count):\n",
        "            page = pdf_document[page_num]\n",
        "            pdf_text += page.get_text(\"text\") + \"\\n\"  # Extract text from each page\n",
        "\n",
        "# Display extracted text (optional, to verify content)\n",
        "print(\"Extracted Text from PDF:\\n\", pdf_text[:1000])  # Display the first 1000 characters as a sample\n",
        "\n",
        "# Initialize the inference client\n",
        "client = InferenceClient(api_key=\"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\")\n",
        "\n",
        "# Prepare a summarization message (you may need to truncate the text for very long PDFs)\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": f\"Please summarize the following text: '{pdf_text[:5000]}'\"}  # Limit to first 5000 characters\n",
        "]\n",
        "\n",
        "# Perform inference and collect response\n",
        "response_text = []\n",
        "stream = client.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "    messages=messages,\n",
        "    temperature=0.5,\n",
        "    max_tokens=500,\n",
        "    top_p=0.7,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "# Collect response chunks\n",
        "for chunk in stream:\n",
        "    response_text.append(chunk.choices[0].delta.content)\n",
        "\n",
        "# Join all chunks into a single formatted string\n",
        "summary = \"\".join(response_text)\n",
        "\n",
        "# Create a JSON response\n",
        "json_response = {\n",
        "    \"summary\": summary\n",
        "}\n",
        "\n",
        "# Print the JSON response\n",
        "print(json.dumps(json_response, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "TQ3-iWHTKAUd",
        "outputId": "59f558e3-350c-4830-812f-8d10c0a355e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8f9993d1-ca31-4005-80ff-b5056ab27726\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8f9993d1-ca31-4005-80ff-b5056ab27726\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Shruti_Mangesh_Sawant_Resume_UPDATED_.pdf to Shruti_Mangesh_Sawant_Resume_UPDATED_.pdf\n",
            "{\n",
            "  \"extracted_text\": \"Shruti Mangesh Sawant\\nThane , India  Phone: 8828554987  Email: sawantshrutim06@gmail.com\\n\\u25fc\\n\\u25fc\\nSUMMARY\\nAn enthusiastic Engineering Graduate Fresher capable and ready to learn and explore the different\\nelements of technical skills and hereby serve the organisation.\\n \\nEDUCATION\\nBachelors in Information Technology\\n-\\nA.P Shah Institute of Technology - Bachelors in Information Technology- 8.10 CGPA\\nVPM Polytechnic -Diploma in Information Technology - 78.94\\nS.K Somaiya Vinaymandir - Stream Science - 58.19\\n \\n2018 \\u2013 2021\\nSSC\\nN.E.H.S - 87.20\\nKEY SKILLS\\nSalesforce\\nHTML\\nPython\\nNetworking and Security\\nArtificial Intelligence\\nIEEE \\nPROFESSIONAL\\nEXPERIENCE\\nIntern.\\nA.P Shah Institute of Technology launched an \\\"INTERNSHIP PROGRAM\\\" called as \\\"APSIT SKILLS\\\"\\nproviding an opportunity explore with a guidance in its steps. The technology used in the internship was\\nSALESFORCE where the exploration of SALESFORCE ECOSYSTEM came in handful for further\\nprogressing in the Internship as well as an individual. It was\",\n",
            "  \"sentiment_analysis_result\": \"After analyzing the policy, I would classify the sentiment as overwhelmingly positive. Here's a breakdown of the reasons:\\n\\n1. **Enthusiastic tone**: The policy starts with a enthusiastic statement about the candidate's capabilities and eagerness to learn and explore technical skills.\\n2. **Academic achievements**: The candidate has a high CGPA (8.10) and has completed various certifications, which demonstrates their academic excellence.\\n3. **Technical skills**: The candidate has listed a range of technical skills, including programming languages (Python, HTML), networking and security, artificial intelligence, and Salesforce.\\n4. **Professional experience**: The candidate has completed an internship and has gained experience in Salesforce, which is a valuable skill in the industry.\\n5. **Achie\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Install Required Libraries\n",
        "\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "from google.colab import files\n",
        "from huggingface_hub import InferenceClient\n",
        "import json\n",
        "\n",
        "# Upload your PDF file containing the policy\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract text from the uploaded PDF file\n",
        "pdf_text = \"\"\n",
        "for filename in uploaded.keys():\n",
        "    with fitz.open(filename) as pdf_document:\n",
        "        for page_num in range(pdf_document.page_count):\n",
        "            page = pdf_document[page_num]\n",
        "            pdf_text += page.get_text(\"text\") + \"\\n\"  # Extract text from each page\n",
        "\n",
        "# Display the extracted text (optional, to verify content)\n",
        "# print(\"Extracted Text from PDF:\\n\", pdf_text[:1000])  # Display the first 1000 characters as a sample\n",
        "\n",
        "# Initialize the inference client\n",
        "client = InferenceClient(api_key=\"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\")\n",
        "\n",
        "# Prepare a sentiment analysis message using the extracted text\n",
        "sentiment_messages = [\n",
        "    {\"role\": \"user\", \"content\": f\"Analyze the sentiment of this policy: '{pdf_text[:5000]}' Please provide a sentiment classification (positive/negative) and a confidence score.\"}  # Limit to first 5000 characters\n",
        "]\n",
        "\n",
        "# Stream the sentiment analysis response\n",
        "sentiment_response = []\n",
        "sentiment_stream = client.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "    messages=sentiment_messages,\n",
        "    temperature=0.5,\n",
        "    max_tokens=150,\n",
        "    top_p=0.7,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "# Collect response chunks for sentiment analysis\n",
        "for chunk in sentiment_stream:\n",
        "    sentiment_response.append(chunk.choices[0].delta.content)\n",
        "\n",
        "# Join the collected response into a single string\n",
        "sentiment_analysis_result = \"\".join(sentiment_response)\n",
        "\n",
        "# Create a JSON response\n",
        "json_response = {\n",
        "    \"extracted_text\": pdf_text[:1000],  # Display first 1000 characters for reference\n",
        "    \"sentiment_analysis_result\": sentiment_analysis_result\n",
        "}\n",
        "\n",
        "# Print the JSON response\n",
        "print(json.dumps(json_response, indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}